{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISS meets TRAK\n",
    "\n",
    "MISS for non-linear model: linearizing as TRAK\n",
    "\n",
    "> The target function is assumed to be the raw logit, i.e., $\\phi(x_{\\text{test}}) = \\theta^\\top x_{\\text{test}} + b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from TRAK.MISS_trak import MISS_TRAK\n",
    "from IF.MISS_IF import MISS_IF\n",
    "from model_train import MLP, SubsetSamper, MNISTModelOutput\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from TRAK.projector import CudaProjector, ProjectionType, BasicProjector\n",
    "from TRAK.grad_calculator import count_parameters, grad_calculator, out_to_loss_grad_calculator\n",
    "from tqdm import tqdm\n",
    "\n",
    "# First, check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "ensemble=5\n",
    "k=5\n",
    "\n",
    "# Load MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "sampler_train = SubsetSamper([i for i in range(5000)])\n",
    "sampler_test = SubsetSamper([0])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, sampler=sampler_train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, sampler=sampler_test)\n",
    "\n",
    "checkpoint_files = [f\"./checkpoint/seed_{seed}_ensemble_{i}.pt\" for i in range(ensemble)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n",
      "#Parameters: 101770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:52<00:00, 95.35it/s]\n",
      "100%|██████████| 5000/5000 [00:03<00:00, 1662.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 222.14it/s]\n",
      " 20%|██        | 1/5 [00:55<03:42, 55.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n",
      "#Parameters: 101770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:51<00:00, 96.68it/s]\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1679.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 262.21it/s]\n",
      " 40%|████      | 2/5 [01:50<02:45, 55.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n",
      "#Parameters: 101770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:52<00:00, 94.91it/s]\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1684.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 255.28it/s]\n",
      " 60%|██████    | 3/5 [02:45<01:50, 55.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n",
      "#Parameters: 101770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:52<00:00, 95.01it/s]\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1705.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 245.17it/s]\n",
      " 80%|████████  | 4/5 [03:41<00:55, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n",
      "#Parameters: 101770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:52<00:00, 94.83it/s]\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1691.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 252.21it/s]\n",
      "100%|██████████| 5/5 [04:37<00:00, 55.45s/it]\n"
     ]
    }
   ],
   "source": [
    "model=MLP().to(device)\n",
    "model_checkpoints=checkpoint_files\n",
    "train_loader=train_loader\n",
    "test_loader=test_loader\n",
    "model_output_class=MNISTModelOutput\n",
    "device=device\n",
    "\n",
    "all_grads_p_list = []\n",
    "Q_list = []\n",
    "\n",
    "for checkpoint_id, checkpoint_file in enumerate(tqdm(model_checkpoints)):\n",
    "    model.load_state_dict(torch.load(checkpoint_file))\n",
    "    model.eval()\n",
    "\n",
    "    print(model)\n",
    "    print(\"#Parameters:\", count_parameters(model))\n",
    "\n",
    "    parameters = list(model.parameters())\n",
    "    normalize_factor = torch.sqrt(torch.tensor(count_parameters(model), dtype=torch.float32))\n",
    "\n",
    "    # projection of the grads\n",
    "    # projector = CudaProjector(grad_dim=count_parameters(model), proj_dim=2048, seed=0, proj_type=ProjectionType.rademacher, device=\"cuda\", max_batch_size=8)\n",
    "    projector = BasicProjector(grad_dim=count_parameters(model), proj_dim=2048, seed=0, proj_type=ProjectionType.rademacher, device=\"cuda\", max_batch_size=8)\n",
    "\n",
    "    # Go through the training loader to get grads\n",
    "    # Φ\n",
    "    all_grads_p = grad_calculator(data_loader=train_loader, model=model, parameters=parameters, func=model_output_class.model_output, normalize_factor=normalize_factor, device=device, projector=projector, checkpoint_id=checkpoint_id)\n",
    "    out_to_loss_grads = out_to_loss_grad_calculator(data_loader=train_loader, model=model, func=model_output_class.get_out_to_loss_grad)\n",
    "    # ϕ\n",
    "    all_grads_test_p = grad_calculator(data_loader=test_loader, model=model, parameters=parameters, func=model_output_class.model_output, normalize_factor=normalize_factor, device=device, projector=projector, checkpoint_id=checkpoint_id)\n",
    "\n",
    "    # Append to list for later averaging\n",
    "    all_grads_p_list.append(all_grads_p)\n",
    "    Q_list.append(out_to_loss_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5000, 2048])\n",
      "torch.Size([5, 4999, 4999])\n",
      "torch.Size([5, 4998, 4998])\n",
      "torch.Size([5, 4997, 4997])\n",
      "torch.Size([5, 4996, 4996])\n",
      "torch.Size([5, 4995, 4995])\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to tensors\n",
    "all_grads_p_tensor = torch.stack(all_grads_p_list)\n",
    "Q_tensor = torch.stack(Q_list)\n",
    "\n",
    "# Initialize MIS tensor\n",
    "num_test_samples = all_grads_test_p.size(0)\n",
    "MIS = torch.zeros(num_test_samples, k, dtype=torch.int32)\n",
    "\n",
    "print(all_grads_p_tensor.shape)\n",
    "# Iterate over each test sample\n",
    "for j in range(num_test_samples):\n",
    "    index = [i for i in range(all_grads_p_tensor.size(1))]\n",
    "    for i in range(k):\n",
    "        avg_Q = torch.mean(Q_tensor, dim=0)\n",
    "        avg_all_grads_p = torch.mean(all_grads_p_tensor, dim=0)\n",
    "        score = all_grads_test_p[j] @ torch.linalg.inv(avg_all_grads_p.T @ avg_all_grads_p) @ avg_all_grads_p.T @ avg_Q\n",
    "        # Select the most influential sample\n",
    "        i_max = score.cpu().detach().numpy().flatten().argsort()[-1]\n",
    "        MIS[j, i] = index[i_max]\n",
    "\n",
    "        Q_tensor = torch.cat([torch.cat([Q_tensor[:, :i, :i], Q_tensor[:, :i, i+1:]], dim=2),torch.cat([Q_tensor[:, i+1:, :i], Q_tensor[:, i+1:, i+1:]], dim=2)],dim=1)\n",
    "        all_grads_p_tensor = torch.cat([all_grads_p_tensor[:, :i_max, :], all_grads_p_tensor[:, i_max+1:, :]], dim=1)\n",
    "        print(Q_tensor.shape)\n",
    "        index = index[:i_max] + index[i_max + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
