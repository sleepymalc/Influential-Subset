{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from actual import actual_effect\n",
    "from IWLS import IWLS, adaptive_IWLS\n",
    "from first_order import first_order, adaptive_first_order\n",
    "from margin import margin\n",
    "\n",
    "from target import target_value\n",
    "from utility import data_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "n = 5000\n",
    "d = 20\n",
    "k = 50\n",
    "isSkewed = True\n",
    "\n",
    "seeds = range(0, 40)\n",
    "covs = [0.5, 1.0, 2.0, 2.5, 3.0, 4.5, 5.0]\n",
    "\n",
    "targets = [\"probability\", \"abs_probability\", \"test_loss\", \"abs_test_loss\", \"avg_abs_test_loss\", \"abs_avg_test_loss\"]\n",
    "\n",
    "methods = [\"IWLS\", \"Adaptive IWLS\", \"Margin-based\", \"First-order\", \"Adaptive First-order\"]\n",
    "num_methods, num_covs, num_seeds = len(methods), len(covs), len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_per_seed_cov(seed, cov, target):\n",
    "    X_train, y_train, X_test, y_test = data_generation(n, d, cov, seed, isSkewed=isSkewed, target=target)\n",
    "    \n",
    "    original_value = target_value(X_train, y_train, X_test, y_test, target=target)\n",
    "    \n",
    "    ind_n, ind_p = margin(X_train, y_train)\n",
    "\n",
    "    scores = np.array([\n",
    "        actual_effect(X_train, y_train, X_test, y_test, IWLS(X_train, y_train, X_test, y_test, target=target)[:k], original_value, target=target), \n",
    "        actual_effect(X_train, y_train, X_test, y_test, adaptive_IWLS(X_train, y_train, X_test, y_test, k=k, target=target), original_value, target=target),\n",
    "        max(actual_effect(X_train, y_train, X_test, y_test, ind_n[:k], original_value, target=target), actual_effect(X_train, y_train, X_test, y_test, ind_p[:k], original_value, target=target)),\n",
    "        actual_effect(X_train, y_train, X_test, y_test, first_order(X_train, y_train, X_test, y_test, target=target)[:k], original_value, target=target),\n",
    "        actual_effect(X_train, y_train, X_test, y_test, adaptive_first_order(X_train, y_train, X_test, y_test, k=k, target=target), original_value, target=target)\n",
    "    ])\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks.shape = (num_methods, num_experiments)\n",
    "def Borda_count(ranks, weights=[5, 4, 3, 2, 1]):\n",
    "    num_methods, num_experiments = ranks.shape\n",
    "\n",
    "    weighted_borda_count = np.zeros((num_methods, num_experiments), dtype=int)\n",
    "\n",
    "    # Calculate weighted Borda count for each seed and covariance\n",
    "    for experiment_idx in range(num_experiments):\n",
    "        # Sort indices based on actual ranks for the current experiment\n",
    "        # tie-handling. ref: https://stackoverflow.com/questions/39059371/can-numpys-argsort-give-equal-element-the-same-rank\n",
    "        def rankmin(x):\n",
    "            u, inv, counts = np.unique(x, return_inverse=True, return_counts=True)\n",
    "            csum = np.zeros_like(counts)\n",
    "            csum[1:] = counts[:-1].cumsum()\n",
    "            return csum[inv]\n",
    "\n",
    "        sorted_indices = rankmin(-1 * ranks[:, experiment_idx])\n",
    "\n",
    "        # Assign weighted Borda count scores\n",
    "        for method_idx, rank in enumerate(sorted_indices):\n",
    "            weighted_borda_count[method_idx, experiment_idx] = weights[rank]\n",
    "            \n",
    "    total_weighted_borda_count = weighted_borda_count.sum(axis=1)\n",
    "\n",
    "    return total_weighted_borda_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: probability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: abs_probability\n",
      "Target: test_loss\n",
      "Target: abs_test_loss\n",
      "Target: avg_abs_test_loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_idx, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(targets):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     scores_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore_per_seed_cov\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcovs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m     scores_array \u001b[38;5;241m=\u001b[39m scores_array\u001b[38;5;241m.\u001b[39mreshape((num_seeds, num_covs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m     scores_method_cov_seed \u001b[38;5;241m=\u001b[39m scores_array\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# method, cov, seed\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/influence/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.conda/envs/influence/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.conda/envs/influence/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/influence/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.conda/envs/influence/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a 2x3 grid of subplots\n",
    "\n",
    "for target_idx, target in enumerate(targets):\n",
    "    print(f\"Target: {target}\")\n",
    "    scores_array = np.array(Parallel(n_jobs=50)(delayed(score_per_seed_cov)(seed, cov, target) for seed in seeds for cov in covs))\n",
    "    scores_array = scores_array.reshape((num_seeds, num_covs, -1))\n",
    "    \n",
    "    scores_method_cov_seed = scores_array.swapaxes(0, 2) # method, cov, seed\n",
    "    scores_cov_method_seed = scores_method_cov_seed.swapaxes(0, 1) # cov, method, seed\n",
    "    \n",
    "    Borda_result = np.zeros((num_covs, num_methods), dtype=float)\n",
    "    \n",
    "    Borda_result = np.array(Parallel(n_jobs=50)(delayed(Borda_count)(scores_cov_method_seed[cov_idx]) for cov_idx in range(num_covs)))\n",
    "\n",
    "    # Plot in the corresponding subplot\n",
    "    row_idx, col_idx = divmod(target_idx, 3)  # Calculate subplot index\n",
    "    for method_idx, method_name in enumerate(methods):\n",
    "        axs[row_idx, col_idx].plot(covs, Borda_result[:, method_idx], label=method_name)\n",
    "        \n",
    "    axs[row_idx, col_idx].set_title(f'Target={target}')\n",
    "    axs[row_idx, col_idx].set_xlabel('Covariance')\n",
    "    axs[row_idx, col_idx].set_ylabel('Borda Count')\n",
    "    axs[row_idx, col_idx].legend(methods)\n",
    "    \n",
    "    axs[row_idx, col_idx].set_xticks(covs)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.suptitle(f'n={n} d={d} k={k}', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_per_seed_cov(seed, cov, target):\n",
    "    X_train, y_train, X_test, y_test = data_generation(n, d, cov, seed, isSkewed=isSkewed, target=target)\n",
    "    \n",
    "    original_value = target_value(X_train, y_train, X_test, y_test, target=target)\n",
    "    \n",
    "    ind_n, ind_p = margin(X_train, y_train)\n",
    "\n",
    "    scores = np.array([\n",
    "        actual_effect(X_train, y_train, X_test, y_test, IWLS(X_train, y_train, X_test, y_test, target=target)[:k], original_value, target=target), \n",
    "        actual_effect(X_train, y_train, X_test, y_test, adaptive_IWLS(X_train, y_train, X_test, y_test, k=k, target=target), original_value, target=target),\n",
    "        max(actual_effect(X_train, y_train, X_test, y_test, ind_n[:k], original_value, target=target), actual_effect(X_train, y_train, X_test, y_test, ind_p[:k], original_value, target=target)),\n",
    "        actual_effect(X_train, y_train, X_test, y_test, first_order(X_train, y_train, X_test, y_test, target=target)[:k], original_value, target=target),\n",
    "        actual_effect(X_train, y_train, X_test, y_test, adaptive_first_order(X_train, y_train, X_test, y_test, k=k, target=target), original_value, target=target)\n",
    "    ])\n",
    "\n",
    "    return np.array([\n",
    "        (scores[0] - scores[2]) / scores[2], \n",
    "        (scores[1] - scores[2]) / scores[2], \n",
    "        1, \n",
    "        (scores[3] - scores[2]) / scores[2], \n",
    "        (scores[4] - scores[2]) / scores[2]\n",
    "    ])\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a 2x3 grid of subplots\n",
    "\n",
    "for target_idx, target in enumerate(targets):\n",
    "    print(f\"Target: {target}\")\n",
    "    ratio_array = np.array(Parallel(n_jobs=50)(delayed(ratio_per_seed_cov)(seed, cov, target) for seed in seeds for cov in covs))\n",
    "    ratio_array = ratio_array.reshape((num_seeds, num_covs, -1))\n",
    "    \n",
    "    ratio_method_cov_seed = ratio_array.swapaxes(0, 2) # method, cov, seed\n",
    "    ratio_cov_method_seed = ratio_method_cov_seed.swapaxes(0, 1) # cov, method, seed\n",
    "    \n",
    "    ratio_result = np.zeros((num_covs, num_methods), dtype=float)\n",
    "    \n",
    "    ratio_result = np.array(Parallel(n_jobs=50)(delayed(Borda_count)(ratio_cov_method_seed[cov_idx]) for cov_idx in range(num_covs)))\n",
    "\n",
    "    # Plot in the corresponding subplot\n",
    "    row_idx, col_idx = divmod(target_idx, 3)  # Calculate subplot index\n",
    "    for method_idx, method_name in enumerate(methods):\n",
    "        axs[row_idx, col_idx].plot(covs, ratio_result[:, method_idx], label=method_name)\n",
    "        \n",
    "    axs[row_idx, col_idx].set_title(f'Target={target}')\n",
    "    axs[row_idx, col_idx].set_xlabel('Covariance')\n",
    "    axs[row_idx, col_idx].set_ylabel('Relative Ratio w.r.t. First-order')\n",
    "    axs[row_idx, col_idx].legend(methods)\n",
    "    \n",
    "    axs[row_idx, col_idx].set_xticks(covs)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.suptitle(f'n={n} d={d} k={k} (Relative Ratio w.r.t. First-order)', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
